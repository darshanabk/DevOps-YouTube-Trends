{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a0fb762",
   "metadata": {
    "papermill": {
     "duration": 0.003768,
     "end_time": "2025-02-03T13:38:37.795792",
     "exception": false,
     "start_time": "2025-02-03T13:38:37.792024",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Country Codes & Continents: A Dataset with ISO 3166-1 Alpha-2\n",
    "\n",
    "This notebook aims to create a dataset of countries, their corresponding ISO 3166-1 Alpha-2 codes, and their respective continents. \n",
    "\n",
    "**Key Features:**\n",
    "\n",
    "* Utilizes the ISO 3166-1 Alpha-2 standard for country codes.\n",
    "* Includes a comprehensive list of countries and their associated continents.\n",
    "* Provides a clean and organized dataset for various data analysis and mapping projects.\n",
    "\n",
    "**Potential Use Cases:**\n",
    "\n",
    "* Geocoding and mapping applications.\n",
    "* Data analysis and visualization projects.\n",
    "* Internationalization and localization tasks.\n",
    "* Building applications that require country-specific information.\n",
    "\n",
    "This notebook demonstrates a simple and efficient approach to gathering and organizing country-related data. \n",
    "\n",
    "**Note:** \n",
    "\n",
    "* Data sources may vary, and the accuracy of the information should be verified independently. \n",
    "<!-- * This is a basic example, and you can further enhance it by adding more details such as country names, currencies, or time zones. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eeea7d8",
   "metadata": {
    "papermill": {
     "duration": 0.00284,
     "end_time": "2025-02-03T13:38:37.801894",
     "exception": false,
     "start_time": "2025-02-03T13:38:37.799054",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# [ISO 3166-1 alpha-2](https://en.wikipedia.org/wiki/ISO_3166-1_alpha-2#References)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db42aa50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-03T13:38:37.809251Z",
     "iopub.status.busy": "2025-02-03T13:38:37.808751Z",
     "iopub.status.idle": "2025-02-03T13:38:37.816541Z",
     "shell.execute_reply": "2025-02-03T13:38:37.815619Z"
    },
    "papermill": {
     "duration": 0.013332,
     "end_time": "2025-02-03T13:38:37.818138",
     "exception": false,
     "start_time": "2025-02-03T13:38:37.804806",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to fetch continent from Wikipedia if pycountry_convert fails\n",
    "def fetch_continent_from_wikipedia(country_name):\n",
    "    \"\"\"Scrape Wikipedia to find the continent of a country.\"\"\"\n",
    "    try:\n",
    "        search_url = f\"https://en.wikipedia.org/wiki/{country_name.replace(' ', '_')}\"\n",
    "        response = requests.get(search_url)\n",
    "        soup = BeautifulSoup(response.text, \"lxml\")\n",
    "\n",
    "        # Define the continent keywords and their codes\n",
    "        continent_keywords = {\n",
    "            \"Africa\": \"AF\", \"Asia\": \"AS\", \"Europe\": \"EU\",\n",
    "            \"North America\": \"NA\", \"South America\": \"SA\",\n",
    "            \"Oceania\": \"OC\", \"Antarctica\": \"AN\"\n",
    "        }\n",
    "\n",
    "        # Search for the continent-related keywords in the page text\n",
    "        for key, code in continent_keywords.items():\n",
    "            if key in soup.text:\n",
    "                return code\n",
    "        \n",
    "        return \"Unknown\"  # If no match is found, return Unknown\n",
    "    except Exception as e:\n",
    "        return \"Unknown\"  # If scraping fails, return Unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "915aefc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-03T13:38:37.824954Z",
     "iopub.status.busy": "2025-02-03T13:38:37.824598Z",
     "iopub.status.idle": "2025-02-03T13:38:37.829396Z",
     "shell.execute_reply": "2025-02-03T13:38:37.828161Z"
    },
    "papermill": {
     "duration": 0.010253,
     "end_time": "2025-02-03T13:38:37.831308",
     "exception": false,
     "start_time": "2025-02-03T13:38:37.821055",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_continent_code(alpha2, country_name):\n",
    "    \"\"\"First, try pycountry_convert, otherwise scrape Wikipedia.\"\"\"\n",
    "    try:\n",
    "        # Try getting the continent code using pycountry_convert\n",
    "        continent_code = pc.country_alpha2_to_continent_code(alpha2)\n",
    "        return continent_code\n",
    "    except KeyError:\n",
    "        # If pycountry_convert fails, scrape Wikipedia\n",
    "        return fetch_continent_from_wikipedia(country_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a621458f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-03T13:38:37.839276Z",
     "iopub.status.busy": "2025-02-03T13:38:37.838846Z",
     "iopub.status.idle": "2025-02-03T13:38:37.847807Z",
     "shell.execute_reply": "2025-02-03T13:38:37.846629Z"
    },
    "papermill": {
     "duration": 0.015232,
     "end_time": "2025-02-03T13:38:37.849773",
     "exception": false,
     "start_time": "2025-02-03T13:38:37.834541",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ISO_3166_1_Alpha_2(it_hub_regions,continent_name_mapping):\n",
    "    # Fetch ISO country data from Wikipedia API\n",
    "    url = \"https://en.wikipedia.org/w/api.php\"\n",
    "    params = {\n",
    "        \"action\": \"parse\",\n",
    "        \"page\": \"ISO_3166-1_alpha-2\",\n",
    "        \"format\": \"json\",\n",
    "        \"prop\": \"text\"\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, params=params)\n",
    "    data = response.json()\n",
    "    page_content = data[\"parse\"][\"text\"][\"*\"] if \"parse\" in data else None\n",
    "    if not page_content:\n",
    "        raise ValueError(\"Failed to fetch data from Wikipedia.\")\n",
    "    \n",
    "    soup = BeautifulSoup(page_content, \"lxml\")\n",
    "    ISO_3166_1_Alpha_2 = {}\n",
    "    \n",
    "    # Find the header and then the table\n",
    "    class_legal = soup.find('h3', id='Officially_assigned_code_elements')\n",
    "    if not class_legal:\n",
    "        raise ValueError(\"Section with id 'Officially_assigned_code_elements' not found.\")\n",
    "    \n",
    "    table = class_legal.find_next(\"table\")\n",
    "    if not table:\n",
    "        raise ValueError(\"Table not found after the header.\")\n",
    "    \n",
    "    # Iterate over each table row to extract country codes and names\n",
    "    for row in table.find_all(\"tr\"):\n",
    "        cells = row.find_all(\"td\")\n",
    "        if len(cells) < 2:\n",
    "            continue  # Skip rows that don't have enough cells\n",
    "        \n",
    "        # Extract ISO alpha-2 country code\n",
    "        code_span = cells[0].find('span', class_=\"monospaced\")\n",
    "        key = code_span.text.strip() if code_span else \"\"\n",
    "        \n",
    "        # Extract country name\n",
    "        link = cells[1].find('a')\n",
    "        value = link.text.strip() if link else \"\"\n",
    "    \n",
    "        # Only add if valid\n",
    "        if key:\n",
    "            # Get continent code (either from pycountry_convert or Wikipedia scraping)\n",
    "            continent_cd = get_continent_code(key, value)\n",
    "            \n",
    "            # Get continent name from the continent code\n",
    "            continent_name = continent_name_mapping.get(continent_cd, \"Unknown\")\n",
    "            \n",
    "            # Check if the country is in the IT hub regions\n",
    "            it_hub_status = \"Yes\" if key in it_hub_regions else \"No\"\n",
    "            \n",
    "            # Store the result in the dictionary\n",
    "            ISO_3166_1_Alpha_2[key] = {\n",
    "                \"country_name\": value,\n",
    "                \"continent\": continent_name, \n",
    "                \"continent_code\": continent_cd, \n",
    "                \"it_hub_country\": it_hub_status\n",
    "            }\n",
    "    \n",
    "\n",
    "    return ISO_3166_1_Alpha_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab3203f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-03T13:38:37.857171Z",
     "iopub.status.busy": "2025-02-03T13:38:37.856779Z",
     "iopub.status.idle": "2025-02-03T13:38:37.863393Z",
     "shell.execute_reply": "2025-02-03T13:38:37.862145Z"
    },
    "papermill": {
     "duration": 0.012433,
     "end_time": "2025-02-03T13:38:37.865303",
     "exception": false,
     "start_time": "2025-02-03T13:38:37.852870",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def RawFile(it_hub_regions,continent_name_mapping):\n",
    "    \"\"\"\n",
    "    Processes video details, structures the data, and saves it as a JSON file.\n",
    "\n",
    "    Args:\n",
    "        max_record_count (int): The maximum number of records to process.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the file is successfully created and saved, False otherwise.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Call the function to structure video details and return a DataFrame.\n",
    "        # `kw_list` is assumed to be a global variable containing the search keyword(s).\n",
    "        dictionary = ISO_3166_1_Alpha_2(it_hub_regions,continent_name_mapping)\n",
    "        \n",
    "        # Check if the DataFrame is not empty before saving.\n",
    "        if dictionary:\n",
    "            \n",
    "            # Generate a timestamp for the file name using the current time in IST (Indian Standard Time).\n",
    "            timestamp = datetime.datetime.now(ist).strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "        \n",
    "            # Create a filename using the generated timestamp to ensure uniqueness with number of records.\n",
    "            filename = f\"R_{timestamp}_country_details.json\"\n",
    "            \n",
    "            with open(filename, \"w\", encoding=\"utf-8\") as file: \n",
    "                json.dump(dictionary, file, indent=4, ensure_ascii=False)\n",
    "            print(f\"dictionary saved as {filename}\")\n",
    "        else:\n",
    "            # Log a message if the DataFrame is empty.\n",
    "            print(\"No data to save since empty dictionary returned.\")\n",
    "        \n",
    "        # Return True indicating the process was successful.\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        # Handle and log any errors that occur during the process.\n",
    "        print(f\"Error during raw file creation: {e}\")\n",
    "        \n",
    "        # Return False indicating the process failed.\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e46e90b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-03T13:38:37.873209Z",
     "iopub.status.busy": "2025-02-03T13:38:37.872833Z",
     "iopub.status.idle": "2025-02-03T13:38:37.881829Z",
     "shell.execute_reply": "2025-02-03T13:38:37.880847Z"
    },
    "papermill": {
     "duration": 0.014933,
     "end_time": "2025-02-03T13:38:37.883688",
     "exception": false,
     "start_time": "2025-02-03T13:38:37.868755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def PushToGithub(repo_url):\n",
    "    # List all files in the working directory\n",
    "    output_files = os.listdir('/kaggle/working')\n",
    "    \n",
    "    try:\n",
    "        # Filter and find the most recent .json file\n",
    "        json_files = [file for file in output_files if file.startswith(\"R_\") and file.endswith(\"_country_details.json\")]\n",
    "        if json_files:\n",
    "            LatestFiles = max(json_files, key=os.path.getctime)  # Get the latest file based on creation time\n",
    "        else:\n",
    "            raise ValueError(\"No JSON files found!\")  # Raise an error if no JSON files are found\n",
    "    except ValueError as e:\n",
    "        print(f\"An error occurred at fetching recent .json file: {e}\")\n",
    "        return False  # Exit the function if there's an error in fetching JSON files\n",
    "    \n",
    "    # Define repository and destination paths\n",
    "    kaggle_repo_url = '/kaggle/working/YouTubeFoodChannelAnalysis'\n",
    "    destination_path = '/kaggle/working/YouTubeFoodChannelAnalysis/Requirement/Daily'\n",
    "\n",
    "    \n",
    "    print(LatestFiles)  # Print the latest JSON file name\n",
    "    try:\n",
    "        # Check if the repository already exists\n",
    "        if os.path.exists(kaggle_repo_url):\n",
    "            print(\"Already cloned and the repo file exists\")\n",
    "            repo = git.Repo(kaggle_repo_url)  # Access the existing repository\n",
    "            origin = repo.remote(name='origin')  # Get the remote repository\n",
    "            origin.pull()  # Pull the latest changes from the repository\n",
    "            print(\"Successfully pulled the git repo before push\")\n",
    "        else:\n",
    "            # Clone the repository if it doesn't exist\n",
    "            repo = git.Repo.clone_from(repo_url, kaggle_repo_url)\n",
    "            print(\"Successfully cloned the git repo\")\n",
    "        \n",
    "        # Check if the destination path exists, and copy the latest file\n",
    "        if os.path.exists(destination_path):\n",
    "            shutil.copyfile(f'/kaggle/working/{LatestFiles}', f'{destination_path}/{LatestFiles}')\n",
    "        else:\n",
    "            # Create the destination directory if it doesn't exist\n",
    "            os.makedirs(destination_path)\n",
    "            shutil.copyfile(f'/kaggle/working/{LatestFiles}', f'{destination_path}/{LatestFiles}')\n",
    "        \n",
    "        # Initialize the repository for git operations\n",
    "        repo = Repo(kaggle_repo_url)\n",
    "        \n",
    "        # Add the copied file to the staging area\n",
    "        repo.index.add([f\"{destination_path}/{LatestFiles}\"])\n",
    "        \n",
    "        timestamp = datetime.datetime.now(ist).strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "        # Commit the changes with a message including the timestamp and file name\n",
    "        repo.index.commit(f\"{timestamp} Added files from Kaggle notebook, {LatestFiles}\")\n",
    "        \n",
    "        # Push the changes to the remote repository\n",
    "        origin = repo.remote(name=\"origin\")\n",
    "        push_result = origin.push()\n",
    "        if push_result:\n",
    "            print(\"Output files successfully pushed to GitHub!\")\n",
    "        else:\n",
    "            print(\"Output files pushed to GitHub failed:(\")\n",
    "        return True  # Return True if the process completes successfully\n",
    "    \n",
    "    except Exception as e:\n",
    "        # Handle any errors that occur during the git automation process\n",
    "        print(f\"An error occurred at git automation code: {e}\")\n",
    "        return False  # Return False if an error occurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d37cf77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-03T13:38:37.891962Z",
     "iopub.status.busy": "2025-02-03T13:38:37.891488Z",
     "iopub.status.idle": "2025-02-03T13:38:37.896635Z",
     "shell.execute_reply": "2025-02-03T13:38:37.895380Z"
    },
    "papermill": {
     "duration": 0.011794,
     "end_time": "2025-02-03T13:38:37.898851",
     "exception": false,
     "start_time": "2025-02-03T13:38:37.887057",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main(repo_url,it_hub_regions,continent_name_mapping):\n",
    "    RawFile(it_hub_regions,continent_name_mapping)\n",
    "    PushToGithub(repo_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8b7b7ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-03T13:38:37.906787Z",
     "iopub.status.busy": "2025-02-03T13:38:37.906301Z",
     "iopub.status.idle": "2025-02-03T13:38:49.081345Z",
     "shell.execute_reply": "2025-02-03T13:38:49.080153Z"
    },
    "papermill": {
     "duration": 11.181215,
     "end_time": "2025-02-03T13:38:49.083185",
     "exception": false,
     "start_time": "2025-02-03T13:38:37.901970",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dictionary saved as R_2025-02-03_19:08:45_country_details.json\n",
      "R_2025-02-03_19:08:45_country_details.json\n",
      "Successfully cloned the git repo\n",
      "Output files successfully pushed to GitHub!\n"
     ]
    }
   ],
   "source": [
    "# Entry point of the script\n",
    "if __name__ == \"__main__\":\n",
    "    import requests\n",
    "    from IPython.display import display,JSON\n",
    "    from bs4 import BeautifulSoup\n",
    "    import pycountry_convert as pc\n",
    "    import datetime\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    import git  \n",
    "    from git import Repo \n",
    "    import shutil  \n",
    "    from pytz import timezone \n",
    "    from datetime import timedelta \n",
    "    import json\n",
    "\n",
    "    # Fetching secrets from Kaggle's secure environment\n",
    "    from kaggle_secrets import UserSecretsClient\n",
    "    user_secrets = UserSecretsClient()\n",
    "    secret_value_0 = user_secrets.get_secret(\"requirementRepoUrl\")  # Fetch the source repository URL\n",
    "    \n",
    "    # Assigning secrets to variables\n",
    "    repo_url = secret_value_0\n",
    "    \n",
    "    # Setting the timezone to Indian Standard Time (IST)\n",
    "    ist = timezone('Asia/Kolkata')\n",
    "    \n",
    "    # List of IT hub regions\n",
    "    it_hub_regions = [\n",
    "        'US',  'IN',  'CN',  'JP',  'KR',  'DE',  'GB',  'FR',  'CA',  'AU',\n",
    "        'SG',  'SE',  'FI',  'IE',  'IL',  'NL',  'CH',  'ES',  'IT',  'BR', \n",
    "        'ZA',  'RU',  'AE',  'TR',  'PL',  'VN',  'MY',  'PH',  'TH',  'ID', \n",
    "        'HK',  'TW',\n",
    "    ]\n",
    "    \n",
    "    # Continent code to continent name mapping\n",
    "    continent_name_mapping = {\n",
    "        \"AF\": \"Africa\",\n",
    "        \"AS\": \"Asia\",\n",
    "        \"EU\": \"Europe\",\n",
    "        \"NA\": \"North America\",\n",
    "        \"SA\": \"South America\",\n",
    "        \"OC\": \"Oceania\",\n",
    "        \"AN\": \"Antarctica\"\n",
    "    }\n",
    "\n",
    "    main(repo_url,it_hub_regions,continent_name_mapping)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30839,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 14.953818,
   "end_time": "2025-02-03T13:38:49.807867",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-03T13:38:34.854049",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
