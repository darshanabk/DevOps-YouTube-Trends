{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "568f105b",
   "metadata": {
    "_cell_guid": "8f1f4da5-a258-4ef9-9bb0-e5a1e7f17a05",
    "_uuid": "fa0e7085-9b0a-4378-8260-b4075d9f668e",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-20T23:14:04.858874Z",
     "iopub.status.busy": "2025-01-20T23:14:04.858525Z",
     "iopub.status.idle": "2025-01-20T23:14:04.867165Z",
     "shell.execute_reply": "2025-01-20T23:14:04.866171Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.014958,
     "end_time": "2025-01-20T23:14:04.868801",
     "exception": false,
     "start_time": "2025-01-20T23:14:04.853843",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def VideoDetailExtraction(kw_list,maxResults = 50):\n",
    "   try:\n",
    "        request = youtube.search().list(part='snippet',\n",
    "                                        order='viewCount',\n",
    "                                        q=kw_list,\n",
    "                                        relevanceLanguage='en',\n",
    "                                        type='video',\n",
    "                                        # videoCategoryId=26, regionCode='IN',\n",
    "                                        maxResults=maxResults,\n",
    "                                        videoCaption = 'closedCaption')\n",
    "                                       \n",
    "        response = request.execute()\n",
    "        return response\n",
    "   except Exception as e:\n",
    "        print(f\"Error during VideoDetailExtraction(): {e}\")\n",
    "        return None\n",
    "\n",
    "def VideoDetailExtractionNextPageToken(kw_list, nextPageToken, maxResults = 50):\n",
    "    try:\n",
    "        request = youtube.search().list(part='snippet',\n",
    "                                        order='viewCount',\n",
    "                                        q=kw_list,\n",
    "                                        relevanceLanguage='en',\n",
    "                                        type='video',\n",
    "                                        # videoCategoryId=26, regionCode='IN',\n",
    "                                        maxResults=maxResults,\n",
    "                                        pageToken=nextPageToken,\n",
    "                                        videoCaption = 'closedCaption')\n",
    "                                        \n",
    "                        \n",
    "        response = request.execute()\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(f\"Error during VideoDetailExtractionNextPageToken(): {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fa59717",
   "metadata": {
    "_cell_guid": "1c9b3012-ad7a-461a-a8ec-48b51dd5b581",
    "_uuid": "231e09e4-5440-4890-9b11-83a4058cbe9d",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-20T23:14:04.876361Z",
     "iopub.status.busy": "2025-01-20T23:14:04.876019Z",
     "iopub.status.idle": "2025-01-20T23:14:04.950675Z",
     "shell.execute_reply": "2025-01-20T23:14:04.949835Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.080119,
     "end_time": "2025-01-20T23:14:04.952297",
     "exception": false,
     "start_time": "2025-01-20T23:14:04.872178",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def VideoDataFrame(response):\n",
    "    try:\n",
    "        videoDetails = []\n",
    "        videoIds = []\n",
    "        channelIds = []\n",
    "\n",
    "        '''\n",
    "        Video Search Block\n",
    "        '''\n",
    "        for i in range(len(response['items'])):\n",
    "            publishedOn = response['items'][i].get('snippet','0000-00-00T00:00:00Z').get('publishTime','0000-00-00T00:00:00Z')\n",
    "            publishTime = re.split(r'[TZ-]',publishedOn)\n",
    "            total_seconds = 0\n",
    "            if not publishedOn == '0000-00-00T00:00:00Z':\n",
    "                dt = datetime.datetime.strptime(publishedOn, \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "                epoch = datetime.datetime(1970, 1, 1)\n",
    "                total_seconds = int((dt - epoch).total_seconds())\n",
    "            videoDetails.append({\n",
    "                'channelId' : response['items'][i]['snippet']['channelId'],\n",
    "                'channelName' : response['items'][i]['snippet']['channelTitle'],\n",
    "                'videoId' : response['items'][i]['id']['videoId'],\n",
    "                'videoTitle' : response['items'][i]['snippet']['title'],\n",
    "                'publishYear' : publishTime[0], #year\n",
    "                'publishMonth' : publishTime[1], #month\n",
    "                'publishDay' : publishTime[2], #day\n",
    "                'publishTime' : publishTime[3], #hh:mm:ss\n",
    "                'publishedOn' : publishedOn,\n",
    "                'publishedOnInSeconds' : total_seconds\n",
    "                })\n",
    "    \n",
    "            videoIds.append(response['items'][i]['id']['videoId'])\n",
    "            channelIds.append(response['items'][i]['snippet']['channelId'])\n",
    "    \n",
    "        print('Video Search Block')\n",
    "        nextPageToken = response.get(\"nextPageToken\",None)\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        Video Block\n",
    "        '''\n",
    "        \n",
    "        request = youtube.videos().list(\n",
    "            part='id,statistics,snippet,contentDetails,localizations,status,liveStreamingDetails,paidProductPlacementDetails,player,recordingDetails,topicDetails',\n",
    "            id=videoIds\n",
    "        )\n",
    "        # print(len(videoIds))\n",
    "        response = request.execute()\n",
    "        \n",
    "        # Ensure videoDetails has at least as many items as the response length.\n",
    "        for i, video in enumerate(response['items']):\n",
    "            if i >= len(videoDetails):  # Ensure no index out of bounds errors\n",
    "                break\n",
    "        \n",
    "            # Fetch video statistics\n",
    "            statistics = video.get('statistics', {})\n",
    "            videoDetails[i]['videoViewCount'] = statistics.get('viewCount', 0)\n",
    "            videoDetails[i]['videoLikeCount'] = statistics.get('likeCount', 0)\n",
    "            videoDetails[i]['videoFavoriteCount'] = statistics.get('favoriteCount', 0)\n",
    "            videoDetails[i]['videoCommentCount'] = statistics.get('commentCount', 0)\n",
    "        \n",
    "            # Fetch video snippet details\n",
    "            snippet = video.get('snippet', {})\n",
    "            videoDetails[i]['videoDescription'] = snippet.get('description', None)\n",
    "            videoDetails[i]['videoTags'] = snippet.get('tags', [])\n",
    "            videoDetails[i]['videoCategoryId'] = snippet.get('categoryId', None)\n",
    "            videoDetails[i]['videoLiveBroadcastContent'] = snippet.get('liveBroadcastContent', None)\n",
    "            videoDetails[i]['videoDefaultLanguage'] = snippet.get('defaultLanguage', None)\n",
    "            videoDetails[i]['videoDefaultAudioLanguage'] = snippet.get('defaultAudioLanguage', None)\n",
    "        \n",
    "            # Handle video duration and convert to seconds\n",
    "            duration = video.get('contentDetails', {}).get('duration', None)\n",
    "            if duration:\n",
    "                match = re.match(r\"PT(?:(\\d+)H)?(?:(\\d+)M)?(?:(\\d+)S)?\", duration)\n",
    "                hours = int(match.group(1) or 0)\n",
    "                minutes = int(match.group(2) or 0)\n",
    "                seconds = int(match.group(3) or 0)\n",
    "                videoDetails[i]['videoDuration'] = timedelta(hours=hours, minutes=minutes, seconds=seconds)\n",
    "                videoDetails[i]['videoDurationInSeconds'] = hours * 3600 + minutes * 60 + seconds\n",
    "            else:\n",
    "                videoDetails[i]['videoDuration'] = None\n",
    "                videoDetails[i]['videoDurationInSeconds'] = None\n",
    "        \n",
    "            # Fetch video content details\n",
    "            content_details = video.get('contentDetails', {})\n",
    "            videoDetails[i]['videoDimension'] = content_details.get('dimension', None)\n",
    "            videoDetails[i]['videoDefinition'] = content_details.get('definition', None)\n",
    "            videoDetails[i]['videoCaption'] = content_details.get('caption', None)\n",
    "            videoDetails[i]['videoLicensedContent'] = content_details.get('licensedContent', False)\n",
    "            videoDetails[i]['videoProjection'] = content_details.get('projection', False)\n",
    "        \n",
    "            # Fetch video status details\n",
    "            status = video.get('status', {})\n",
    "            videoDetails[i]['videoUploadStatus'] = status.get('uploadStatus', None)\n",
    "            videoDetails[i]['videoPrivacyStatus'] = status.get('privacyStatus', None)\n",
    "            videoDetails[i]['videoLicense'] = status.get('license', None)\n",
    "            videoDetails[i]['videoEmbeddable'] = status.get('embeddable', False)\n",
    "            videoDetails[i]['videoPublicStatsViewable'] = status.get('publicStatsViewable', False)\n",
    "            videoDetails[i]['videoMadeForKids'] = status.get('madeForKids', False)\n",
    "            videoDetails[i]['videoHasPaidProductPlacement'] = status.get('hasPaidProductPlacement', False)\n",
    "        \n",
    "            # Fetch video player details\n",
    "            player = video.get('player', {})\n",
    "            videoDetails[i]['videoPlayerEmbedHtml'] = player.get('embedHtml', None)\n",
    "        \n",
    "            # Fetch recording details\n",
    "            recording_details = video.get('recordingDetails', {})\n",
    "            videoDetails[i]['videoRecordingLocationDescription'] = recording_details.get('locationDescription', None)\n",
    "            videoDetails[i]['videoRecordingDate'] = recording_details.get('recordingDate', None)\n",
    "        \n",
    "            # Fetch location within recording details\n",
    "            location = recording_details.get('location', {})\n",
    "            videoDetails[i]['videoRecordingLocationLatitude'] = location.get('latitude', 0)\n",
    "            videoDetails[i]['videoRecordingLocationLongitude'] = location.get('longitude', 0)\n",
    "            videoDetails[i]['videoRecordingLocationAltitude'] = location.get('altitude', 0)\n",
    "        \n",
    "            # Fetch topic details\n",
    "            videoDetails[i]['videotopicDetailsUrls'] = video.get('topicDetails', {}).get('topicCategories', [])\n",
    "        \n",
    "        # Ensure that videoDetails has been populated correctly before returning\n",
    "        print(\"Video Block\")\n",
    "\n",
    "\n",
    "        '''\n",
    "        Channel Block\n",
    "        '''\n",
    "        request = youtube.channels().list(part='id,contentDetails,brandingSettings,contentOwnerDetails,localizations,snippet,statistics,status,topicDetails',\n",
    "                                           id=channelIds)\n",
    "        # print(len(channelIds))\n",
    "        \n",
    "        response = request.execute()\n",
    "        \n",
    "        # Make sure videoDetails has at least as many items as the response length.\n",
    "        for i, channel in enumerate(response['items']):\n",
    "            if i >= len(videoDetails):  # Ensure no index out of bounds errors\n",
    "                break\n",
    "        \n",
    "            videoDetails[i]['channelDescription'] = channel['snippet'].get('description', None)\n",
    "            videoDetails[i]['channelCustomUrl'] = channel['snippet'].get('customUrl', None)\n",
    "            \n",
    "            # Handle publish time parsing correctly.\n",
    "            publishedOn = channel['snippet'].get('publishTime', '0000-00-00T00:00:00Z')\n",
    "            publishTime = re.split(r'[TZ-]', publishedOn)\n",
    "            total_seconds = 0\n",
    "            if publishedOn != '0000-00-00T00:00:00Z':\n",
    "                dt = datetime.datetime.strptime(publishedOn, \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "                epoch = datetime.datetime(1970, 1, 1)\n",
    "                total_seconds = int((dt - epoch).total_seconds())\n",
    "                \n",
    "            videoDetails[i]['channelPublishYear'] = publishTime[0]  # year\n",
    "            videoDetails[i]['channelPublishMonth'] = publishTime[1]  # month\n",
    "            videoDetails[i]['channelPublishDay'] = publishTime[2]  # day\n",
    "            videoDetails[i]['channelPublishTime'] = publishTime[3]  # hh:mm:ss\n",
    "            videoDetails[i]['channelPublishedOn'] = publishedOn\n",
    "            videoDetails[i]['channelPublishedOnInSeconds'] = total_seconds\n",
    "            videoDetails[i]['channelCountry'] = channel['snippet'].get('country', None)\n",
    "            \n",
    "            # Handle thumbnails and avoid KeyError\n",
    "            thumbnails = channel['snippet'].get('thumbnails', {})\n",
    "            videoDetails[i]['channelThumbnailDefaultUrl'] = thumbnails.get('default', {}).get('url', None)\n",
    "            videoDetails[i]['channelThumbnailDefaultWidth'] = thumbnails.get('default', {}).get('width', 0)\n",
    "            videoDetails[i]['channelThumbnailDefaultHeight'] = thumbnails.get('default', {}).get('height', 0)\n",
    "            videoDetails[i]['channelThumbnailMediumUrl'] = thumbnails.get('medium', {}).get('url', None)\n",
    "            videoDetails[i]['channelThumbnailMediumWidth'] = thumbnails.get('medium', {}).get('width', 0)\n",
    "            videoDetails[i]['channelThumbnailMediumHeight'] = thumbnails.get('medium', {}).get('height', 0)\n",
    "            videoDetails[i]['channelThumbnailHighUrl'] = thumbnails.get('high', {}).get('url', None)\n",
    "            videoDetails[i]['channelThumbnailHighWidth'] = thumbnails.get('high', {}).get('width', 0)\n",
    "            videoDetails[i]['channelThumbnailHighHeight'] = thumbnails.get('high', {}).get('height', 0)\n",
    "        \n",
    "            # Handle contentDetails and statistics data\n",
    "            contentDetails = channel.get('contentDetails', {}).get('relatedPlaylists', {})\n",
    "            videoDetails[i]['channelPlaylistsLikes'] = contentDetails.get('likes', 0)\n",
    "            videoDetails[i]['channelPlaylistsUploads'] = contentDetails.get('uploads', None)\n",
    "            \n",
    "            statistics = channel.get('statistics', {})\n",
    "            videoDetails[i]['channelViewCount'] = statistics.get('viewCount', 0)\n",
    "            videoDetails[i]['channelSubscriberCount'] = statistics.get('subscriberCount', 0)\n",
    "            videoDetails[i]['channelHiddenSubscriberCount'] = statistics.get('hiddenSubscriberCount', 0)\n",
    "            videoDetails[i]['channelVideoCount'] = statistics.get('videoCount', 0)\n",
    "        \n",
    "            # Handle topicDetails and status\n",
    "            videoDetails[i]['channelTopicCategories'] = channel.get('topicDetails', {}).get('topicCategories', [])\n",
    "            videoDetails[i]['channelPrivacyStatus'] = channel.get('status', {}).get('privacyStatus', None)\n",
    "            videoDetails[i]['channelIsLinked'] = channel.get('status', {}).get('isLinked', False)\n",
    "            videoDetails[i]['channelLongUploadsStatus'] = channel.get('status', {}).get('longUploadsStatus', None)\n",
    "            videoDetails[i]['channelMadeForKids'] = channel.get('status', {}).get('madeForKids', False)\n",
    "            \n",
    "            # Handle brandingSettings and other optional fields\n",
    "            brandingSettings = channel.get('brandingSettings', {}).get('channel', {})\n",
    "            videoDetails[i]['channelKeywords'] = brandingSettings.get('keywords', None)\n",
    "            videoDetails[i]['channelAnalyticsAccountId'] = brandingSettings.get('trackingAnalyticsAccountId', None)\n",
    "            videoDetails[i]['channelBrandCountry'] = brandingSettings.get('country', None)\n",
    "            \n",
    "            brandingImage = channel.get('brandingSettings', {}).get('image', {})\n",
    "            videoDetails[i]['channelBannerExternalUrl'] = brandingImage.get('bannerExternalUrl', None)\n",
    "        \n",
    "        # Ensure that videoDetails has been populated correctly before returning\n",
    "        print(\"Channel Block\")\n",
    "\n",
    "        # display(videoDetails)\n",
    "        videoDetails = pd.DataFrame(videoDetails)\n",
    "\n",
    "        return videoDetails,nextPageToken  \n",
    "    except Exception as e:\n",
    "        print(f\"Error while processing VideoDataFrame(): {e}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bea5ce98",
   "metadata": {
    "_cell_guid": "122e22a5-68f8-40d8-86e8-fa7382e4f8ec",
    "_uuid": "bae23e23-1bbd-4954-a1ba-aa174ce94c29",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-20T23:14:04.959084Z",
     "iopub.status.busy": "2025-01-20T23:14:04.958788Z",
     "iopub.status.idle": "2025-01-20T23:14:04.966791Z",
     "shell.execute_reply": "2025-01-20T23:14:04.965795Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.012884,
     "end_time": "2025-01-20T23:14:04.968194",
     "exception": false,
     "start_time": "2025-01-20T23:14:04.955310",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def VideoDetailsStructuring(max_record_count,kw_list):\n",
    "    try:\n",
    "        videoDetails = pd.DataFrame()\n",
    "        nextPageToken = None\n",
    "        record_fetching_batches = [50]\n",
    "        if max_record_count>50:\n",
    "            quotient = max_record_count // 50  # Integer division\n",
    "            remainder = [max_record_count % 50]  # Remainder\n",
    "            record_fetching_batches = record_fetching_batches*quotient\n",
    "            if remainder[0] > 0:\n",
    "                record_fetching_batches.extend(remainder)\n",
    "            print(record_fetching_batches)\n",
    "        else:\n",
    "            record_fetching_batches = [max_record_count]\n",
    "            \n",
    "        if len(record_fetching_batches) == 1:            \n",
    "            response = VideoDetailExtraction(kw_list,record_fetching_batches[0])\n",
    "            if response is None:\n",
    "                print(\"Failed to fetch initial video details - VideoDetailExtraction() returned None, hence returned empty DataFrame.\")\n",
    "                return pd.DataFrame()\n",
    "                \n",
    "\n",
    "            videoDetails, nextPageToken = VideoDataFrame(response)\n",
    "            nextPageToken = None\n",
    "            if videoDetails is None:\n",
    "                print(\"Failed to process video data frame - VideoDataFrame() returned None, hence returned empty DataFrame.\")\n",
    "                return pd.DataFrame()\n",
    "            return videoDetails\n",
    "        \n",
    "        elif len(record_fetching_batches) > 1:\n",
    "            response = VideoDetailExtraction(kw_list,record_fetching_batches[0])\n",
    "            if response is None:\n",
    "                print(\"Failed to fetch initial video details - VideoDetailExtraction() returned None, hence returned empty DataFrame.\")\n",
    "                return pd.DataFrame()\n",
    "                    \n",
    "            videoDetails, nextPageToken = VideoDataFrame(response)\n",
    "            if videoDetails is None:\n",
    "                print(\"Failed to process video data frame - VideoDataFrame() returned None, hence returned empty DataFrame.\")\n",
    "                return pd.DataFrame()\n",
    "\n",
    "            for batch in record_fetching_batches[1:]:\n",
    "                response = VideoDetailExtractionNextPageToken(kw_list, nextPageToken, batch)\n",
    "                if response is None:\n",
    "                    print(\"Failed to fetch next page of video details - VideoDetailExtractionNextPageToken() returned None, hence returned till now fetched videoDetails.\")\n",
    "                    break\n",
    "                videoDetails_next, nextPageToken = VideoDataFrame(response)\n",
    "                if videoDetails_next is not None:\n",
    "                    # videoDetails = videoDetails.append(videoDetails_next, ignore_index=True) # DataFrame has no opbject append\n",
    "                    videoDetails = pd.concat([videoDetails, videoDetails_next], ignore_index=True)\n",
    "                # Break the loop if we've reached the max record count or no more pages\n",
    "                if len(videoDetails) >= max_record_count or not nextPageToken:\n",
    "                    break\n",
    "      \n",
    "        return videoDetails\n",
    "    except Exception as e:\n",
    "        print(f\"Error during VideoDetailsStructuring(), hence returned empty DataFrame: {e}\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b33cc95",
   "metadata": {
    "_cell_guid": "ebce2b3b-bfd4-4a20-8b83-70e44515996c",
    "_uuid": "1705540d-26d3-4a1d-8013-737370d33cf0",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-20T23:14:04.974830Z",
     "iopub.status.busy": "2025-01-20T23:14:04.974549Z",
     "iopub.status.idle": "2025-01-20T23:14:04.979364Z",
     "shell.execute_reply": "2025-01-20T23:14:04.978548Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.009695,
     "end_time": "2025-01-20T23:14:04.980855",
     "exception": false,
     "start_time": "2025-01-20T23:14:04.971160",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def RawFile(max_record_count):\n",
    "    try:\n",
    "        timestamp = datetime.datetime.now(ist).strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "        filename = f\"{timestamp}.json\"\n",
    "        # Save the DataFrame as a JSON file\n",
    "        dataframe = VideoDetailsStructuring(max_record_count,kw_list)\n",
    "        if not dataframe.empty:\n",
    "            dataframe.to_json(filename, orient=\"records\", indent=4)\n",
    "            print(f\"DataFrame saved as {filename}\")\n",
    "        else:\n",
    "            print(\"No data to save since empty DataFrame returned.\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error during raw file creation: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88346a59",
   "metadata": {
    "_cell_guid": "decbb10c-d948-43a7-8ce3-aa5056d71382",
    "_uuid": "5f66f7a7-64ab-4981-8571-e671ca9ae562",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-20T23:14:04.989134Z",
     "iopub.status.busy": "2025-01-20T23:14:04.988811Z",
     "iopub.status.idle": "2025-01-20T23:14:04.997340Z",
     "shell.execute_reply": "2025-01-20T23:14:04.996282Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.013947,
     "end_time": "2025-01-20T23:14:04.999086",
     "exception": false,
     "start_time": "2025-01-20T23:14:04.985139",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def PushToGithub():\n",
    "    output_files = os.listdir('/kaggle/working')\n",
    "    try:\n",
    "        # Find the most recent .json file\n",
    "        json_files = [file for file in output_files if file.endswith(\".json\")]\n",
    "        \n",
    "        if json_files:\n",
    "            LatestFiles = max(json_files, key=os.path.getctime)\n",
    "        else:\n",
    "            raise ValueError(\"No JSON files found!\")\n",
    "\n",
    "    except ValueError as e:\n",
    "        print(f\"An error occurred at fetching recent .json file: {e}\")\n",
    "        return\n",
    "        \n",
    "    kaggle_repo_url = '/kaggle/working/YouTubeFoodChannelAnalysis'\n",
    "    destination_path = '/kaggle/working/YouTubeFoodChannelAnalysis/Source/Daily'\n",
    "    \n",
    "    print(LatestFiles)\n",
    "    try:\n",
    "        if os.path.exists(kaggle_repo_url):\n",
    "            print(\"cloned and the repo file exist\")\n",
    "            repo = git.Repo(kaggle_repo_url) \n",
    "            origin = repo.remote(name='origin') \n",
    "            origin.pull()\n",
    "            print(\"successfully pulled the git repo\")\n",
    "        else:\n",
    "            #repo_url Global\n",
    "            repo = git.Repo.clone_from(repo_url, kaggle_repo_url)\n",
    "            print(\"successfully cloned the git repo\")\n",
    "    \n",
    "        \n",
    "        if os.path.exists(destination_path):\n",
    "            shutil.copyfile(f'/kaggle/working/{LatestFiles}', f'{destination_path}/{LatestFiles}')\n",
    "                \n",
    "        else:\n",
    "            os.makedirs(destination_path)\n",
    "            shutil.copyfile(f'/kaggle/working/{LatestFiles}', f'{destination_path}/{LatestFiles}')\n",
    "           \n",
    "                \n",
    "        repo = Repo(kaggle_repo_url)\n",
    "        # repo.git.add(all=True)\n",
    "        repo.index.add([f\"{destination_path}/{LatestFiles}\"])\n",
    "        timestamp = datetime.datetime.now(ist).strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "        repo.index.commit(f\"{timestamp} Added files from Kaggle notebook, {LatestFiles}\")\n",
    "        origin = repo.remote(name=\"origin\")\n",
    "        origin.push()\n",
    "        print(\"Output files successfully pushed to GitHub!\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred at git automation code: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fe55a7b",
   "metadata": {
    "_cell_guid": "7c43f2b6-20f0-4112-b590-ccb6ca0fa100",
    "_uuid": "cda78dce-5109-43f8-904b-4d1b79c4f72d",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-20T23:14:05.006023Z",
     "iopub.status.busy": "2025-01-20T23:14:05.005714Z",
     "iopub.status.idle": "2025-01-20T23:14:05.009619Z",
     "shell.execute_reply": "2025-01-20T23:14:05.008646Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.008923,
     "end_time": "2025-01-20T23:14:05.011083",
     "exception": false,
     "start_time": "2025-01-20T23:14:05.002160",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main(max_record_count):\n",
    "    RawFile(max_record_count)\n",
    "    PushToGithub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d4dc216",
   "metadata": {
    "_cell_guid": "29d56ea6-2415-478c-b41a-822ed2337249",
    "_uuid": "f03428f1-6776-4604-87cc-8156171d8b23",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-20T23:14:05.017841Z",
     "iopub.status.busy": "2025-01-20T23:14:05.017485Z",
     "iopub.status.idle": "2025-01-20T23:14:12.160373Z",
     "shell.execute_reply": "2025-01-20T23:14:12.159251Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 7.14817,
     "end_time": "2025-01-20T23:14:12.162224",
     "exception": false,
     "start_time": "2025-01-20T23:14:05.014054",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50, 50, 50, 50]\n",
      "Video Search Block\n",
      "Video Block\n",
      "Channel Block\n",
      "Video Search Block\n",
      "Video Block\n",
      "Channel Block\n",
      "Video Search Block\n",
      "Video Block\n",
      "Channel Block\n",
      "Video Search Block\n",
      "Video Block\n",
      "Channel Block\n",
      "DataFrame saved as 2025-01-21_04:44:07.json\n",
      "2025-01-21_04:44:07.json\n",
      "successfully cloned the git repo\n",
      "Output files successfully pushed to GitHub!\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    from googleapiclient.discovery import build\n",
    "    from IPython.display import JSON, display\n",
    "    import re\n",
    "    import datetime\n",
    "    from dateutil.relativedelta import relativedelta\n",
    "    import pandas as pd\n",
    "    import os\n",
    "    from kaggle_secrets import UserSecretsClient\n",
    "    import git\n",
    "    from git import Repo\n",
    "    import shutil\n",
    "    from pytz import timezone\n",
    "    from datetime import timedelta\n",
    "\n",
    "    from kaggle_secrets import UserSecretsClient\n",
    "    user_secrets = UserSecretsClient()\n",
    "    secret_value_0 = user_secrets.get_secret(\"sourceApiKey\")\n",
    "    secret_value_1 = user_secrets.get_secret(\"sourceRepoUrl\")\n",
    "\n",
    "    api_key = secret_value_0\n",
    "    repo_url = secret_value_1\n",
    "    api_service_name = \"youtube\"\n",
    "    api_version = \"v3\"\n",
    "    youtube = build(api_service_name, api_version, developerKey=api_key)\n",
    "\n",
    "    ist = timezone('Asia/Kolkata')\n",
    "    max_record_count = 200\n",
    "    kw_list =  \"devops\"\n",
    "    main(max_record_count)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30839,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 10.741788,
   "end_time": "2025-01-20T23:14:12.784904",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-01-20T23:14:02.043116",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
