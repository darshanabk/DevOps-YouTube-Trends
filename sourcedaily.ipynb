{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c7b8ae8",
   "metadata": {
    "_cell_guid": "8f1f4da5-a258-4ef9-9bb0-e5a1e7f17a05",
    "_uuid": "fa0e7085-9b0a-4378-8260-b4075d9f668e",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-21T20:03:45.180729Z",
     "iopub.status.busy": "2025-01-21T20:03:45.180172Z",
     "iopub.status.idle": "2025-01-21T20:03:45.189011Z",
     "shell.execute_reply": "2025-01-21T20:03:45.187794Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.016562,
     "end_time": "2025-01-21T20:03:45.190910",
     "exception": false,
     "start_time": "2025-01-21T20:03:45.174348",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def VideoDetailExtraction(kw_list,maxResults = 50):\n",
    "   try:\n",
    "        request = youtube.search().list(part='snippet',\n",
    "                                        order='viewCount',\n",
    "                                        q=kw_list,\n",
    "                                        relevanceLanguage='en',\n",
    "                                        type='video',\n",
    "                                        # videoCategoryId=26, regionCode='IN',\n",
    "                                        maxResults=maxResults,\n",
    "                                        videoCaption = 'closedCaption')\n",
    "                                       \n",
    "        response = request.execute()\n",
    "        return response\n",
    "   except Exception as e:\n",
    "        print(f\"Error during VideoDetailExtraction(): {e}\")\n",
    "        return None\n",
    "\n",
    "def VideoDetailExtractionNextPageToken(kw_list, nextPageToken, maxResults = 50):\n",
    "    try:\n",
    "        request = youtube.search().list(part='snippet',\n",
    "                                        order='viewCount',\n",
    "                                        q=kw_list,\n",
    "                                        relevanceLanguage='en',\n",
    "                                        type='video',\n",
    "                                        # videoCategoryId=26, regionCode='IN',\n",
    "                                        maxResults=maxResults,\n",
    "                                        pageToken=nextPageToken,\n",
    "                                        videoCaption = 'closedCaption')\n",
    "                                        \n",
    "                        \n",
    "        response = request.execute()\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(f\"Error during VideoDetailExtractionNextPageToken(): {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aca2fb36",
   "metadata": {
    "_cell_guid": "1c9b3012-ad7a-461a-a8ec-48b51dd5b581",
    "_uuid": "231e09e4-5440-4890-9b11-83a4058cbe9d",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-21T20:03:45.199830Z",
     "iopub.status.busy": "2025-01-21T20:03:45.199453Z",
     "iopub.status.idle": "2025-01-21T20:03:45.229680Z",
     "shell.execute_reply": "2025-01-21T20:03:45.228484Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.036831,
     "end_time": "2025-01-21T20:03:45.231702",
     "exception": false,
     "start_time": "2025-01-21T20:03:45.194871",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def VideoDataFrame(response):\n",
    "    try:\n",
    "        videoDetails = []\n",
    "        videoIds = []\n",
    "        channelIds = []\n",
    "        channelDetails = []\n",
    "        '''\n",
    "        Video Search Block\n",
    "        '''\n",
    "        for i in range(len(response['items'])):\n",
    "            publishedOn = response['items'][i].get('snippet','0000-00-00T00:00:00Z').get('publishTime','0000-00-00T00:00:00Z')\n",
    "            publishTime = re.split(r'[TZ-]',publishedOn)\n",
    "            total_seconds = 0\n",
    "            if not publishedOn == '0000-00-00T00:00:00Z':\n",
    "                dt = datetime.datetime.strptime(publishedOn, \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "                epoch = datetime.datetime(1970, 1, 1)\n",
    "                total_seconds = int((dt - epoch).total_seconds())\n",
    "            videoDetails.append({\n",
    "                'channelId' : response['items'][i]['snippet']['channelId'],\n",
    "                'channelName' : response['items'][i]['snippet']['channelTitle'],\n",
    "                'videoId' : response['items'][i]['id']['videoId'],\n",
    "                'videoTitle' : response['items'][i]['snippet']['title'],\n",
    "                'publishYear' : publishTime[0], #year\n",
    "                'publishMonth' : publishTime[1], #month\n",
    "                'publishDay' : publishTime[2], #day\n",
    "                'publishTime' : publishTime[3], #hh:mm:ss\n",
    "                'publishedOn' : publishedOn,\n",
    "                'publishedOnInSeconds' : total_seconds\n",
    "                })\n",
    "    \n",
    "            videoIds.append(response['items'][i]['id']['videoId'])\n",
    "            channelIds.append(response['items'][i]['snippet']['channelId'])\n",
    "    \n",
    "        # print('Video Search Block')\n",
    "        nextPageToken = response.get(\"nextPageToken\",None)\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        Video Block\n",
    "        '''\n",
    "        \n",
    "        request = youtube.videos().list(\n",
    "            part='id,statistics,snippet,contentDetails,localizations,status,liveStreamingDetails,paidProductPlacementDetails,player,recordingDetails,topicDetails',\n",
    "            id=videoIds\n",
    "        )\n",
    "        # print(len(videoIds))\n",
    "        response = request.execute()\n",
    "        \n",
    "    \n",
    "        for i in range(len(response['items'])):\n",
    "            video = response['items'][i]\n",
    "            # Fetch video statistics\n",
    "            videoDetails[i]['videoUniqueId'] = video['id']\n",
    "            statistics = video.get('statistics', {})\n",
    "            videoDetails[i]['videoViewCount'] = statistics.get('viewCount', 0)\n",
    "            videoDetails[i]['videoLikeCount'] = statistics.get('likeCount', 0)\n",
    "            videoDetails[i]['videoFavoriteCount'] = statistics.get('favoriteCount', 0)\n",
    "            videoDetails[i]['videoCommentCount'] = statistics.get('commentCount', 0)\n",
    "        \n",
    "            # Fetch video snippet details\n",
    "            snippet = video.get('snippet', {})\n",
    "            videoDetails[i]['videoDescription'] = snippet.get('description', None)\n",
    "            videoDetails[i]['videoTags'] = snippet.get('tags', [])\n",
    "            videoDetails[i]['videoCategoryId'] = snippet.get('categoryId', None)\n",
    "            videoDetails[i]['videoLiveBroadcastContent'] = snippet.get('liveBroadcastContent', None)\n",
    "            videoDetails[i]['videoDefaultLanguage'] = snippet.get('defaultLanguage', None)\n",
    "            videoDetails[i]['videoDefaultAudioLanguage'] = snippet.get('defaultAudioLanguage', None)\n",
    "        \n",
    "            # Handle video duration and convert to seconds\n",
    "            duration = video.get('contentDetails', {}).get('duration', None)\n",
    "            if duration:\n",
    "                match = re.match(r\"PT(?:(\\d+)H)?(?:(\\d+)M)?(?:(\\d+)S)?\", duration)\n",
    "                hours = int(match.group(1) or 0)\n",
    "                minutes = int(match.group(2) or 0)\n",
    "                seconds = int(match.group(3) or 0)\n",
    "                videoDetails[i]['videoDuration'] = timedelta(hours=hours, minutes=minutes, seconds=seconds)\n",
    "                videoDetails[i]['videoDurationInSeconds'] = hours * 3600 + minutes * 60 + seconds\n",
    "            else:\n",
    "                videoDetails[i]['videoDuration'] = None\n",
    "                videoDetails[i]['videoDurationInSeconds'] = None\n",
    "        \n",
    "            # Fetch video content details\n",
    "            content_details = video.get('contentDetails', {})\n",
    "            videoDetails[i]['videoDimension'] = content_details.get('dimension', None)\n",
    "            videoDetails[i]['videoDefinition'] = content_details.get('definition', None)\n",
    "            videoDetails[i]['videoCaption'] = content_details.get('caption', None)\n",
    "            videoDetails[i]['videoLicensedContent'] = content_details.get('licensedContent', False)\n",
    "            videoDetails[i]['videoProjection'] = content_details.get('projection', False)\n",
    "        \n",
    "            # Fetch video status details\n",
    "            status = video.get('status', {})\n",
    "            videoDetails[i]['videoUploadStatus'] = status.get('uploadStatus', None)\n",
    "            videoDetails[i]['videoPrivacyStatus'] = status.get('privacyStatus', None)\n",
    "            videoDetails[i]['videoLicense'] = status.get('license', None)\n",
    "            videoDetails[i]['videoEmbeddable'] = status.get('embeddable', False)\n",
    "            videoDetails[i]['videoPublicStatsViewable'] = status.get('publicStatsViewable', False)\n",
    "            videoDetails[i]['videoMadeForKids'] = status.get('madeForKids', False)\n",
    "            videoDetails[i]['videoHasPaidProductPlacement'] = status.get('hasPaidProductPlacement', False)\n",
    "        \n",
    "            # Fetch video player details\n",
    "            player = video.get('player', {})\n",
    "            videoDetails[i]['videoPlayerEmbedHtml'] = player.get('embedHtml', None)\n",
    "        \n",
    "            # Fetch recording details\n",
    "            recording_details = video.get('recordingDetails', {})\n",
    "            videoDetails[i]['videoRecordingLocationDescription'] = recording_details.get('locationDescription', None)\n",
    "            videoDetails[i]['videoRecordingDate'] = recording_details.get('recordingDate', None)\n",
    "        \n",
    "            # Fetch location within recording details\n",
    "            location = recording_details.get('location', {})\n",
    "            videoDetails[i]['videoRecordingLocationLatitude'] = location.get('latitude', 0)\n",
    "            videoDetails[i]['videoRecordingLocationLongitude'] = location.get('longitude', 0)\n",
    "            videoDetails[i]['videoRecordingLocationAltitude'] = location.get('altitude', 0)\n",
    "        \n",
    "            # Fetch topic details\n",
    "            videoDetails[i]['videotopicDetailsUrls'] = video.get('topicDetails', {}).get('topicCategories', [])\n",
    "        \n",
    "        # Ensure that videoDetails has been populated correctly before returning\n",
    "        # print(\"Video Block\")\n",
    "\n",
    "\n",
    "        '''\n",
    "        Channel Block\n",
    "        '''\n",
    "        videoDetails = pd.DataFrame(videoDetails)\n",
    "\n",
    "        Unique_ChannelIds = list(set(videoDetails['channelId']))\n",
    "\n",
    "        request = youtube.channels().list(part='id,contentDetails,brandingSettings,contentOwnerDetails,localizations,snippet,statistics,status,topicDetails',\n",
    "                                          id=Unique_ChannelIds)\n",
    "\n",
    "        response = request.execute()\n",
    "\n",
    "        for i in range(len(response['items'])):\n",
    "            item = response['items'][i]\n",
    "            snippet = item.get('snippet',{})\n",
    "            publishedOn = snippet.get('publishedAt','0000-00-00T00:00:00Z')\n",
    "            publishedAt =  re.split(r'[TZ-]', publishedOn)\n",
    "            total_seconds = 0\n",
    "            # if publishedOn != '0000-00-00T00:00:00Z':\n",
    "            #     dt = datetime.datetime.strptime(publishedOn, \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "            #     epoch = datetime.datetime(1970, 1, 1)\n",
    "            #     total_seconds = int((dt - epoch).total_seconds())\n",
    "            if publishedOn != '0000-00-00T00:00:00Z':\n",
    "                try:\n",
    "                    dt = datetime.datetime.strptime(publishedOn, \"%Y-%m-%dT%H:%M:%S.%fZ\")  # Updated format\n",
    "                except ValueError:\n",
    "                    dt = datetime.datetime.strptime(publishedOn, \"%Y-%m-%dT%H:%M:%SZ\")  # Fallback for no microseconds\n",
    "                epoch = datetime.datetime(1970, 1, 1)\n",
    "                total_seconds = int((dt - epoch).total_seconds())\n",
    "\n",
    "            thumbnails = item['snippet'].get('thumbnails', {})\n",
    "            contentDetails = item.get('contentDetails', {}).get('relatedPlaylists', {})\n",
    "            statistics = item.get('statistics', {})\n",
    "            brandingSettings = item.get('brandingSettings', {}).get('channel', {})\n",
    "            brandingImage = item.get('brandingSettings', {}).get('image', {})\n",
    "            \n",
    "            channelDetails.append({\n",
    "            'channelIdUnique':item['id'],\n",
    "            'channelTitleCheck': snippet.get('title',None),\n",
    "            'channelDescription': snippet.get('description',None),\n",
    "            'channelCustomUrl': snippet.get('customUrl',None),\n",
    "        \n",
    "            'channelPublishYear': publishTime[0],  # year\n",
    "            'channelPublishMonth': publishTime[1], # month\n",
    "            'channelPublishDay': publishTime[2],  # day\n",
    "            'channelPublishTime': publishTime[3],  # hh:mm:ss\n",
    "            'channelPublishedOn': publishedOn,\n",
    "            'channelPublishedOnInSeconds': total_seconds,\n",
    "            'channelCountry': item['snippet'].get('country', None),\n",
    "        \n",
    "            # Handle thumbnails and avoid KeyError\n",
    "            'channelThumbnailDefaultUrl': thumbnails.get('default', {}).get('url', None),\n",
    "            'channelThumbnailDefaultWidth': thumbnails.get('default', {}).get('width', 0),\n",
    "            'channelThumbnailDefaultHeight': thumbnails.get('default', {}).get('height', 0),\n",
    "            'channelThumbnailMediumUrl': thumbnails.get('medium', {}).get('url', None),\n",
    "            'channelThumbnailMediumWidth': thumbnails.get('medium', {}).get('width', 0),\n",
    "            'channelThumbnailMediumHeight': thumbnails.get('medium', {}).get('height', 0),\n",
    "            'channelThumbnailHighUrl': thumbnails.get('high', {}).get('url', None),\n",
    "            'channelThumbnailHighWidth': thumbnails.get('high', {}).get('width', 0),\n",
    "            'channelThumbnailHighHeight': thumbnails.get('high', {}).get('height', 0),\n",
    "        \n",
    "            # Handle contentDetails and statistics data\n",
    "            'channelPlaylistsLikes': contentDetails.get('likes', 0),\n",
    "            'channelPlaylistsUploads': contentDetails.get('uploads', None),\n",
    "        \n",
    "            'channelViewCount': statistics.get('viewCount', 0),\n",
    "            'channelSubscriberCount': statistics.get('subscriberCount', 0),\n",
    "            'channelHiddenSubscriberCount': statistics.get('hiddenSubscriberCount', 0),\n",
    "            'channelVideoCount': statistics.get('videoCount', 0),\n",
    "        \n",
    "            # Handle topicDetails and status\n",
    "            'channelTopicCategories': item.get('topicDetails', {}).get('topicCategories', []),\n",
    "            'channelPrivacyStatus': item.get('status', {}).get('privacyStatus', None),\n",
    "            'channelIsLinked': item.get('status', {}).get('isLinked', False),\n",
    "            'channelLongUploadsStatus': item.get('status', {}).get('longUploadsStatus', None),\n",
    "            'channelMadeForKids': item.get('status', {}).get('madeForKids', False),\n",
    "        \n",
    "            # Handle brandingSettings and other optional fields\n",
    "            'channelKeywords': brandingSettings.get('keywords', None),\n",
    "            'channelAnalyticsAccountId': brandingSettings.get('trackingAnalyticsAccountId', None),\n",
    "            'channelBrandCountry': brandingSettings.get('country', None),\n",
    "        \n",
    "            'channelBannerExternalUrl': brandingImage.get('bannerExternalUrl', None)\n",
    "            })\n",
    "        channelDetails = pd.DataFrame(channelDetails)\n",
    "        # display(channelDetails)\n",
    "                \n",
    "        # print(\"Channel Block\")\n",
    "\n",
    "        #Result\n",
    "        resultDataFrame = pd.merge(videoDetails, channelDetails, left_on='channelId', right_on='channelIdUnique', how='left')\n",
    "        # print(\"ResultDataFrame\")\n",
    "        return resultDataFrame,nextPageToken  \n",
    "    except Exception as e:\n",
    "        print(f\"Error while processing VideoDataFrame(): {e}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03603de3",
   "metadata": {
    "_cell_guid": "122e22a5-68f8-40d8-86e8-fa7382e4f8ec",
    "_uuid": "bae23e23-1bbd-4954-a1ba-aa174ce94c29",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-21T20:03:45.239679Z",
     "iopub.status.busy": "2025-01-21T20:03:45.239266Z",
     "iopub.status.idle": "2025-01-21T20:03:45.248592Z",
     "shell.execute_reply": "2025-01-21T20:03:45.247495Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.015616,
     "end_time": "2025-01-21T20:03:45.250681",
     "exception": false,
     "start_time": "2025-01-21T20:03:45.235065",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def VideoDetailsStructuring(max_record_count,kw_list):\n",
    "    try:\n",
    "        resultDataFrame = pd.DataFrame()\n",
    "        nextPageToken = None\n",
    "        record_fetching_batches = [50]\n",
    "        if max_record_count>50:\n",
    "            quotient = max_record_count // 50  # Integer division\n",
    "            remainder = [max_record_count % 50]  # Remainder\n",
    "            record_fetching_batches = record_fetching_batches*quotient\n",
    "            if remainder[0] > 0:\n",
    "                record_fetching_batches.extend(remainder)\n",
    "            # print(len(record_fetching_batches))\n",
    "        else:\n",
    "            record_fetching_batches = [max_record_count]\n",
    "            \n",
    "        if len(record_fetching_batches) == 1:            \n",
    "            response = VideoDetailExtraction(kw_list,record_fetching_batches[0])\n",
    "            if response is None:\n",
    "                print(\"Failed to fetch initial video details - VideoDetailExtraction() returned None, hence returned empty DataFrame.\")\n",
    "                return pd.DataFrame()\n",
    "                \n",
    "\n",
    "            resultDataFrame, nextPageToken = VideoDataFrame(response)\n",
    "            nextPageToken = None\n",
    "            if resultDataFrame is None:\n",
    "                print(\"Failed to process video data frame - VideoDataFrame() returned None, hence returned empty DataFrame.\")\n",
    "                return pd.DataFrame()\n",
    "            return resultDataFrame\n",
    "        \n",
    "        elif len(record_fetching_batches) > 1:\n",
    "            response = VideoDetailExtraction(kw_list,record_fetching_batches[0])\n",
    "            if response is None:\n",
    "                print(\"Failed to fetch initial video details - VideoDetailExtraction() returned None, hence returned empty DataFrame.\")\n",
    "                return pd.DataFrame()\n",
    "                    \n",
    "            resultDataFrame, nextPageToken = VideoDataFrame(response)\n",
    "            if resultDataFrame is None:\n",
    "                print(\"Failed to process video data frame - VideoDataFrame() returned None, hence returned empty DataFrame.\")\n",
    "                return pd.DataFrame()\n",
    "\n",
    "            for batch in record_fetching_batches[1:]:\n",
    "                response = VideoDetailExtractionNextPageToken(kw_list, nextPageToken, batch)\n",
    "                if response is None:\n",
    "                    print(\"Failed to fetch next page of video details - VideoDetailExtractionNextPageToken() returned None, hence returned till now fetched videoDetails.\")\n",
    "                    break\n",
    "                resultDataFrame_next, nextPageToken = VideoDataFrame(response)\n",
    "                if resultDataFrame_next is not None:\n",
    "                    # videoDetails = videoDetails.append(videoDetails_next, ignore_index=True) # DataFrame has no opbject append\n",
    "                    resultDataFrame = pd.concat([resultDataFrame, resultDataFrame_next], ignore_index=True)\n",
    "                # Break the loop if we've reached the max record count or no more pages\n",
    "                if len(resultDataFrame) >= max_record_count or not nextPageToken:\n",
    "                    break\n",
    "      \n",
    "        return resultDataFrame\n",
    "    except Exception as e:\n",
    "        print(f\"Error during VideoDetailsStructuring(), hence returned empty DataFrame: {e}\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fc1bbfe",
   "metadata": {
    "_cell_guid": "ebce2b3b-bfd4-4a20-8b83-70e44515996c",
    "_uuid": "1705540d-26d3-4a1d-8013-737370d33cf0",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-21T20:03:45.258596Z",
     "iopub.status.busy": "2025-01-21T20:03:45.258132Z",
     "iopub.status.idle": "2025-01-21T20:03:45.263949Z",
     "shell.execute_reply": "2025-01-21T20:03:45.262911Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.011958,
     "end_time": "2025-01-21T20:03:45.265971",
     "exception": false,
     "start_time": "2025-01-21T20:03:45.254013",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def RawFile(max_record_count):\n",
    "    try:\n",
    "        timestamp = datetime.datetime.now(ist).strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "        filename = f\"{timestamp}.json\"\n",
    "        # Save the DataFrame as a JSON file\n",
    "        dataframe = VideoDetailsStructuring(max_record_count,kw_list)\n",
    "        if not dataframe.empty:\n",
    "            dataframe.to_json(filename, orient=\"records\", indent=4)\n",
    "            print(f\"DataFrame saved as {filename}\")\n",
    "        else:\n",
    "            print(\"No data to save since empty DataFrame returned.\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error during raw file creation: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0da32fb5",
   "metadata": {
    "_cell_guid": "decbb10c-d948-43a7-8ce3-aa5056d71382",
    "_uuid": "5f66f7a7-64ab-4981-8571-e671ca9ae562",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-21T20:03:45.275225Z",
     "iopub.status.busy": "2025-01-21T20:03:45.274806Z",
     "iopub.status.idle": "2025-01-21T20:03:45.283515Z",
     "shell.execute_reply": "2025-01-21T20:03:45.282275Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.014344,
     "end_time": "2025-01-21T20:03:45.285176",
     "exception": false,
     "start_time": "2025-01-21T20:03:45.270832",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def PushToGithub():\n",
    "    output_files = os.listdir('/kaggle/working')\n",
    "    try:\n",
    "        # Find the most recent .json file\n",
    "        json_files = [file for file in output_files if file.endswith(\".json\")]\n",
    "        \n",
    "        if json_files:\n",
    "            LatestFiles = max(json_files, key=os.path.getctime)\n",
    "        else:\n",
    "            raise ValueError(\"No JSON files found!\")\n",
    "\n",
    "    except ValueError as e:\n",
    "        print(f\"An error occurred at fetching recent .json file: {e}\")\n",
    "        return\n",
    "        \n",
    "    kaggle_repo_url = '/kaggle/working/YouTubeFoodChannelAnalysis'\n",
    "    destination_path = '/kaggle/working/YouTubeFoodChannelAnalysis/Source/Daily'\n",
    "    \n",
    "    print(LatestFiles)\n",
    "    try:\n",
    "        if os.path.exists(kaggle_repo_url):\n",
    "            print(\"Already cloned and the repo file exist\")\n",
    "            repo = git.Repo(kaggle_repo_url) \n",
    "            origin = repo.remote(name='origin') \n",
    "            origin.pull()\n",
    "            print(\"successfully pulled the git repo before push\")\n",
    "        else:\n",
    "            #repo_url Global\n",
    "            repo = git.Repo.clone_from(repo_url, kaggle_repo_url)\n",
    "            print(\"successfully cloned the git repo\")\n",
    "    \n",
    "        \n",
    "        if os.path.exists(destination_path):\n",
    "            shutil.copyfile(f'/kaggle/working/{LatestFiles}', f'{destination_path}/{LatestFiles}')\n",
    "                \n",
    "        else:\n",
    "            os.makedirs(destination_path)\n",
    "            shutil.copyfile(f'/kaggle/working/{LatestFiles}', f'{destination_path}/{LatestFiles}')\n",
    "           \n",
    "                \n",
    "        repo = Repo(kaggle_repo_url)\n",
    "        # repo.git.add(all=True)\n",
    "        repo.index.add([f\"{destination_path}/{LatestFiles}\"])\n",
    "        timestamp = datetime.datetime.now(ist).strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "        repo.index.commit(f\"{timestamp} Added files from Kaggle notebook, {LatestFiles}\")\n",
    "        origin = repo.remote(name=\"origin\")\n",
    "        origin.push()\n",
    "        print(\"Output files successfully pushed to GitHub!\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred at git automation code: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f141f7d",
   "metadata": {
    "_cell_guid": "7c43f2b6-20f0-4112-b590-ccb6ca0fa100",
    "_uuid": "cda78dce-5109-43f8-904b-4d1b79c4f72d",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-21T20:03:45.292420Z",
     "iopub.status.busy": "2025-01-21T20:03:45.291984Z",
     "iopub.status.idle": "2025-01-21T20:03:45.296724Z",
     "shell.execute_reply": "2025-01-21T20:03:45.295499Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.010446,
     "end_time": "2025-01-21T20:03:45.298715",
     "exception": false,
     "start_time": "2025-01-21T20:03:45.288269",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main(max_record_count):\n",
    "    RawFile(max_record_count)\n",
    "    PushToGithub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b62836ad",
   "metadata": {
    "_cell_guid": "29d56ea6-2415-478c-b41a-822ed2337249",
    "_uuid": "f03428f1-6776-4604-87cc-8156171d8b23",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-21T20:03:45.306645Z",
     "iopub.status.busy": "2025-01-21T20:03:45.306288Z",
     "iopub.status.idle": "2025-01-21T20:03:57.427425Z",
     "shell.execute_reply": "2025-01-21T20:03:57.426157Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 12.12717,
     "end_time": "2025-01-21T20:03:57.429293",
     "exception": false,
     "start_time": "2025-01-21T20:03:45.302123",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved as 2025-01-22_01:33:47.json\n",
      "2025-01-22_01:33:47.json\n",
      "successfully cloned the git repo\n",
      "Output files successfully pushed to GitHub!\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    from googleapiclient.discovery import build\n",
    "    from IPython.display import JSON, display\n",
    "    import re\n",
    "    import datetime\n",
    "    from dateutil.relativedelta import relativedelta\n",
    "    import pandas as pd\n",
    "    import os\n",
    "    from kaggle_secrets import UserSecretsClient\n",
    "    import git\n",
    "    from git import Repo\n",
    "    import shutil\n",
    "    from pytz import timezone\n",
    "    from datetime import timedelta\n",
    "\n",
    "    from kaggle_secrets import UserSecretsClient\n",
    "    user_secrets = UserSecretsClient()\n",
    "    secret_value_0 = user_secrets.get_secret(\"sourceApiKey\")\n",
    "    secret_value_1 = user_secrets.get_secret(\"sourceRepoUrl\")\n",
    "\n",
    "    api_key = secret_value_0\n",
    "    repo_url = secret_value_1\n",
    "    api_service_name = \"youtube\"\n",
    "    api_version = \"v3\"\n",
    "    youtube = build(api_service_name, api_version, developerKey=api_key)\n",
    "\n",
    "    ist = timezone('Asia/Kolkata')\n",
    "    max_record_count = 3000\n",
    "    kw_list =  \"devops\"\n",
    "    main(max_record_count)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30839,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 16.064252,
   "end_time": "2025-01-21T20:03:58.356342",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-01-21T20:03:42.292090",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
